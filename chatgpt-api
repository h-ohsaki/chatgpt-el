#!/usr/bin/env /home/ohsaki/src/chatgpt-el/venv/bin/python3
#
# 
# Copyright (c) 2025, Hiroyuki Ohsaki.
# All rights reserved.
#
# $Id: chat,v 1.10 2025/07/15 08:23:32 ohsaki Exp $
#

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

import sys

from openai import OpenAI
from perlcompat import die, warn, getopts
# import tbdump

#                       Output	Intel	Speed	Cutoff
# gpt-4.1-nano 		$0.40	2	5	2024-06-01
# gpt-4o-mini  		$0.60	2	4	2023-10-01
# gpt-3.5-turbo		$1.50	1	2	2021-09-01
# gpt-4.1-mini 		$1.60	3	4	2024-06-01
# o1-mini		$4.4	R3	2	2023-10-01
# o3-mini		$4.4	R4	3	2024-10-01
# o4-mini		$4.4	R4	3	2024-06-01
# o3			$8	R5	1	2024-06-01
# gpt-4o	 	$10.0	3	3	2023-10-01
# gpt-4-turbo  		$30.0	2	3	2023-12-01
# o1			$60.0	R4	1	2023-10-01

INSTRUCTIONS = """\
あなたは親切で信頼できる優秀な AI アドバイザです。
ユーザーの質問意図をくみ取り、
論理的な文章を心がけてください。

読者は情報工学分野で、
ネットワークアーキテクチャを専門分野とする大学教員です。
情報工学や情報ネットワークに関する基本的な事柄は説明する必要がありません。

文章は自然な日本語で、
必要に応じて段落や箇条書き、
表現の工夫 (例や補足) を使って Markdown 形式で説明してください。
不要な繰り返しは避けながら、
有益な情報をできるだけ多く提供してください。

専門用語には元となる英語を括弧書きで表記してください。

事実やエビデンスを重視して回答してください。
最新の研究やデータに基づいた情報を提供してください。
事実に関する質問に答える際、
自身の知識だけで 100% の確信が持てない場合は、
決して推測で答えないでください。
代わりに「情報が確認できなかった」と答えてください。

誤解されることが多い概念には、
どのように誤解されることが多いか例とともに示してください。

もし可能であれば、
より深く学ぶために役立つと思われる、
周辺情報や、エピソード、類似した概念との関係性を説明してください。
"""

def usage():
    die(f"""\
usage: {sys.argv[0]} [-vc] [-e engine] [-m model] [-s query]
  -v         verbose mode
  -c         compare mode (also diplay the reply from gpt-4.1-mini)
  -e engine  specify AI engine (default: chatgpt)
  -m model   specify LLM model (default: gpt-4o-mini)
  -i instr   specify instructions
  -s query   query string
""")

def run_query(client, model, instructions, query, max_output_tokens=8192, temperature=0): 
    print(f'[{model}]')
    stream = client.responses.create(
        model=model,
        instructions=instructions,
        input=query,
        stream=True,
        max_output_tokens=max_output_tokens,
        temperature=temperature,
    )
    for event in stream:
        try:
            delta = event.delta
            print(delta, end='', flush=True)
        except AttributeError:
            pass
    print()

def main():
    opt = getopts('vce:m:i:s:') or usage()
    verbose = opt.v
    compare = opt.c
    engine = opt.e or 'chatgpt'
    model = opt.m or 'gpt-4.1-mini'
    instructions = opt.i or INSTRUCTIONS
    query = opt.s

    client = OpenAI()
    run_query(client, model, instructions, query)

    if compare:
        print('----------------------------------------------------------------')
        run_query(client, 'gpt-4.1-mini', INSTRUCTIONS, query)
        
if __name__ == "__main__":
    main()
